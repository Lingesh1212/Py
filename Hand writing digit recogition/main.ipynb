{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1K2KVI7UqBzPLf3f9afhYETbgzhD7mtSH","authorship_tag":"ABX9TyMyWpBcRQ3ueQRf1hmMH86x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"xsw8lFadS7iE","executionInfo":{"status":"error","timestamp":1697794920351,"user_tz":-330,"elapsed":15,"user":{"displayName":"Lingeshwaran A","userId":"09505652601940402707"}},"outputId":"00b10593-fd21-4e45-dccf-0ace2b385867"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cdbd580bc534>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mRandInitialize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPrediction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Model'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from scipy.io import loadmat\n","import numpy as np\n","from Model import neural_network\n","from RandInitialize import initialise\n","from Prediction import predict\n","from scipy.optimize import minimize\n","\n","\n","# Loading mat file\n","data = loadmat('mnist-original.mat')\n","\n","# Extracting features from mat file\n","X = data['data']\n","X = X.transpose()\n","\n","# Normalizing the data\n","X = X / 255\n","\n","# Extracting labels from mat file\n","y = data['label']\n","y = y.flatten()\n","\n","# Splitting data into training set with 60,000 examples\n","X_train = X[:60000, :]\n","y_train = y[:60000]\n","\n","# Splitting data into testing set with 10,000 examples\n","X_test = X[60000:, :]\n","y_test = y[60000:]\n","\n","m = X.shape[0]\n","input_layer_size = 784 # Images are of (28 X 28) px so there will be 784 features\n","hidden_layer_size = 100\n","num_labels = 10 # There are 10 classes [0, 9]\n","\n","# Randomly initialising Thetas\n","initial_Theta1 = initialise(hidden_layer_size, input_layer_size)\n","initial_Theta2 = initialise(num_labels, hidden_layer_size)\n","\n","# Unrolling parameters into a single column vector\n","initial_nn_params = np.concatenate((initial_Theta1.flatten(), initial_Theta2.flatten()))\n","maxiter = 100\n","lambda_reg = 0.1 # To avoid overfitting\n","myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, y_train, lambda_reg)\n","\n","# Calling minimize function to minimize cost function and to train weights\n","results = minimize(neural_network, x0=initial_nn_params, args=myargs,\n","\t\toptions={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac=True)\n","\n","nn_params = results[\"x\"] # Trained Theta is extracted\n","\n","# Weights are split back to Theta1, Theta2\n","Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (\n","\t\t\t\t\t\t\thidden_layer_size, input_layer_size + 1)) # shape = (100, 785)\n","Theta2 = np.reshape(nn_params[hidden_layer_size * (input_layer_size + 1):],\n","\t\t\t\t\t(num_labels, hidden_layer_size + 1)) # shape = (10, 101)\n","\n","# Checking test set accuracy of our model\n","pred = predict(Theta1, Theta2, X_test)\n","print('Test Set Accuracy: {:f}'.format((np.mean(pred == y_test) * 100)))\n","\n","# Checking train set accuracy of our model\n","pred = predict(Theta1, Theta2, X_train)\n","print('Training Set Accuracy: {:f}'.format((np.mean(pred == y_train) * 100)))\n","\n","# Evaluating precision of our model\n","true_positive = 0\n","for i in range(len(pred)):\n","\tif pred[i] == y_train[i]:\n","\t\ttrue_positive += 1\n","false_positive = len(y_train) - true_positive\n","print('Precision =', true_positive/(true_positive + false_positive))\n","\n","# Saving Thetas in .txt file\n","np.savetxt('Theta1.txt', Theta1, delimiter=' ')\n","np.savetxt('Theta2.txt', Theta2, delimiter=' ')\n"]}]}